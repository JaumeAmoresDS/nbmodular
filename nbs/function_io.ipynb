{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function_io\n",
    "\n",
    "> I/O functions used for loading / saving results and local variables from function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core.function_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pdb\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "import shlex\n",
    "from dataclasses import dataclass\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import ast\n",
    "import logging\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "from IPython import get_ipython\n",
    "from IPython.core.magic import (Magics, magics_class, line_magic,\n",
    "                                cell_magic, line_cell_magic)\n",
    "from IPython.core.magic_arguments import (argument, magic_arguments, parse_argstring)\n",
    "import ipynbname\n",
    "from sklearn.utils import Bunch\n",
    "from fastcore.all import argnames\n",
    "import nbdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_df (path, **kwargs):\n",
    "    path=Path(path)\n",
    "    path_without_extension=path.parent / path.name[:-len('.df')]\n",
    "    if (path_without_extension.parent / f'{path_without_extension.name}.parquet').exists():\n",
    "        df = pd.read_parquet (path_without_extension.parent / f'{path_without_extension.name}.parquet', **kwargs)\n",
    "    elif (path_without_extension.parent / f'{path_without_extension.name}.pk').exists():\n",
    "        df = pd.read_parquet (path_without_extension.parent / f'{path_without_extension.name}.pk', **kwargs)\n",
    "    elif (path_without_extension.parent / f'{path_without_extension.name}.csv').exists():\n",
    "        df = pd.read_parquet (path_without_extension.parent / f'{path_without_extension.name}.csv', **kwargs)\n",
    "    else:\n",
    "        raise RuntimeError (f'File {path} not found')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_df (df, path, **kwargs):\n",
    "    path=Path(path)\n",
    "    path.parent.mkdir (parents=True, exist_ok=True)\n",
    "    name_without_extension = path.name[:-len('.df')]\n",
    "    extension = ''\n",
    "    try:\n",
    "        df.to_parquet (path.parent / f'{name_without_extension}.parquet', **kwargs)\n",
    "        extension='parquet'\n",
    "    except:\n",
    "        try:\n",
    "            df.to_pickle (path.parent / f'{name_without_extension}.pk', **kwargs)\n",
    "            extension='pickle'\n",
    "        except:\n",
    "            df.to_csv (path.parent / f'{name_without_extension}.csv', **kwargs)\n",
    "            extension='csv'\n",
    "    with open (path, 'wt') as f: \n",
    "        f.write (extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_pickle (path, **kwargs):\n",
    "    return joblib.load (path, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_pickle (data, path, **kwargs):\n",
    "    joblib.dump (data, path, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_csv (path, **kwargs):\n",
    "    return pd.read_csv (path, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_csv (df, path, **kwargs):\n",
    "    df.to_csv (path, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_parquet (path, **kwargs):\n",
    "    return pd.read_parquet (path, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_parquet (df, path, **kwargs):\n",
    "    df.to_parquet (path, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _load_structured (structure, io_type_load_args={}):\n",
    "    if structure['single']:\n",
    "        io_type = structure['io_type']\n",
    "        load_args={} if io_type not in io_type_load_args else io_type_load_args[io_type]\n",
    "        data = load (\n",
    "            structure['path'], \n",
    "            io_type=io_type,\n",
    "            **load_args,\n",
    "        )\n",
    "    elif structure['list_like']:\n",
    "        data = []\n",
    "        for i, element_structure in enumerate (structure['structure']):\n",
    "            element = _load_structured (element_structure, io_type_load_args)\n",
    "            data.append (element)\n",
    "        if structure['io_type'] != 'list':\n",
    "            type_data = eval(structure['io_type'])\n",
    "            try:\n",
    "                data = type_data (data)\n",
    "            except:\n",
    "                pass\n",
    "    elif structure['dict_like']:\n",
    "        data = {}\n",
    "        for k, element_structure in structure['structure'].items():\n",
    "            element = _load_structured (element_structure, io_type_load_args)\n",
    "            data[k] = element\n",
    "        if structure['io_type'] != 'dict':\n",
    "            if structure['io_type']=='Bunch':\n",
    "                data = Bunch (**data)\n",
    "            else:\n",
    "                type_data = eval(structure['io_type'])\n",
    "                try:\n",
    "                    data = type_data (data)\n",
    "                except:\n",
    "                    pass\n",
    "    return data\n",
    "\n",
    "def load_structured (path, **kwargs):\n",
    "    path = Path(path)\n",
    "    with open (path / 'structure.json', 'rt') as f:\n",
    "        structure = json.load (f)\n",
    "    return _load_structured (structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _is_inhomogeneous (data, max_length=100, types=[pd.DataFrame]):\n",
    "    inhomogeneous=False\n",
    "    try:\n",
    "        _ = np.array (data, float)\n",
    "    except:\n",
    "        try:\n",
    "            _ = np.array (data, str)\n",
    "        except:\n",
    "            inhomogeneous=True\n",
    "    if not inhomogeneous and len(data)<max_length:\n",
    "        for t in types:\n",
    "            if all (map(lambda x: isinstance(x, t), data)):\n",
    "                return True\n",
    "    return inhomogeneous\n",
    "\n",
    "def _save_structured (\n",
    "    data,\n",
    "    path,\n",
    "    io_types={pd.DataFrame: {'io_type': 'df', 'save_args': {}}},\n",
    "    list_like_types=[list, tuple, np.ndarray],\n",
    "    dict_like_types=[dict]\n",
    "):\n",
    "    for type_element in io_types:\n",
    "        if isinstance (data, type_element):\n",
    "            io_type = io_types[type_element]['io_type']\n",
    "            save_args = io_types[type_element]['save_args']\n",
    "            path = path / f'data.{io_type}'\n",
    "            save (data, path, io_type=io_type, **save_args)\n",
    "            structure = {'io_type': io_type, 'single': True, 'path': str(path), 'structure': None, 'list_like': False, 'dict_like': False}\n",
    "            return structure\n",
    "        \n",
    "    if any (map (lambda t: isinstance (data, t), list_like_types)):\n",
    "        if _is_inhomogeneous (data):\n",
    "            structure = {\n",
    "                'io_type': type (data).__name__,\n",
    "                'single': False,\n",
    "                'path': str(path),\n",
    "                'structure': [],\n",
    "                'list_like': True, \n",
    "                'dict_like': False,\n",
    "            }\n",
    "            for i, element in enumerate (data):\n",
    "                element_structure = _save_structured (\n",
    "                    element, \n",
    "                    path / str(i), \n",
    "                    io_types=io_types,\n",
    "                    list_like_types=list_like_types,\n",
    "                    dict_like_types=dict_like_types,\n",
    "                )\n",
    "                structure['structure'].append (element_structure)\n",
    "        else:\n",
    "            path = path / 'data.pickle'\n",
    "            save (data, path, io_type='pickle')\n",
    "            structure = {'io_type': 'pickle', 'single': True, 'path': str(path), 'structure': None}\n",
    "        \n",
    "    elif any (map (lambda t: isinstance (data, t), dict_like_types)):\n",
    "        structure = {\n",
    "            'io_type': type (data).__name__,\n",
    "            'single': False,\n",
    "            'path': str(path),\n",
    "            'structure': {},\n",
    "            'list_like': False, \n",
    "            'dict_like': True,\n",
    "        }\n",
    "        for k, element in data.items():\n",
    "            element_structure = _save_structured (\n",
    "                element, \n",
    "                path / k, \n",
    "                io_types=io_types,\n",
    "                list_like_types=list_like_types,\n",
    "                dict_like_types=dict_like_types,\n",
    "            )\n",
    "            structure['structure'][k] = element_structure\n",
    "    else:\n",
    "        raise ValueError (f'Invalid data type: {type(data)}')\n",
    "    \n",
    "    return structure\n",
    "\n",
    "def save_structured (\n",
    "    data,\n",
    "    path,\n",
    "    io_types={pd.DataFrame: {'io_type': 'df', 'save_args': {}}},\n",
    "    list_like_types=[list, tuple, np.ndarray],\n",
    "    dict_like_types=[dict],\n",
    "    make_relative=True,\n",
    "    **kwargs,\n",
    "):\n",
    "    if make_relative:\n",
    "        current_dir = str (Path('.').absolute())\n",
    "        path = str(path).replace (current_dir, '')\n",
    "        if len(path) > 0 and path[0]=='/':\n",
    "            path = path[1:]\n",
    "    path = Path (path)\n",
    "    structure = _save_structured (\n",
    "        data,\n",
    "        path,\n",
    "        io_types=io_types,\n",
    "        list_like_types=list_like_types,\n",
    "        dict_like_types=dict_like_types,\n",
    "    )\n",
    "    with open (path / 'structure.json', 'wt') as f:\n",
    "        json.dump (structure, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load (\n",
    "    path_variables,\n",
    "    io_type='pickle',\n",
    "    **kwargs,\n",
    "):\n",
    "    load_function = eval (f'load_{io_type}')\n",
    "    return load_function (path_variables, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save (\n",
    "    data,\n",
    "    path_variables,\n",
    "    io_type='pickle',\n",
    "    **kwargs,\n",
    "):\n",
    "    Path(path_variables).parent.mkdir (parents=True, exist_ok=True)\n",
    "    save_function = eval (f'save_{io_type}')\n",
    "    save_function (data, path_variables, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\n",
    "        'numbers' :[1,2,3],\n",
    "        'table': pd.DataFrame ([[1,2],[3,4]], columns=['a','b'], index=['this','that']),\n",
    "        'vector': np.array ([10,20,30]),\n",
    "    },\n",
    "    pd.DataFrame ([[11,21,31],[31,41,51]], columns=['c','d','e'], index=['i0','i1']),\n",
    "    [1000,2000,3000],\n",
    "    pd.DataFrame ([[101,201],[301,401]], columns=['e','f']),\n",
    "]\n",
    "save_structured (data, 'test_structured')\n",
    "assert sorted(os.listdir('test_structured'))==['0', '1', '2', '3', 'structure.json']\n",
    "assert sorted(os.listdir('test_structured/0'))==sorted(['table', 'vector', 'numbers'])\n",
    "assert sorted(os.listdir('test_structured/0/table'))==sorted(['data.parquet', 'data.df'])\n",
    "assert os.listdir('test_structured/0/vector')==['data.pickle']\n",
    "assert os.listdir('test_structured/0/numbers')==['data.pickle']\n",
    "assert sorted(os.listdir('test_structured/1')) == sorted(['data.parquet', 'data.df'])\n",
    "assert os.listdir('test_structured/2')==['data.pickle']\n",
    "assert sorted(os.listdir('test_structured/3'))==sorted(['data.parquet', 'data.df'])\n",
    "data2 = load_structured ('test_structured')\n",
    "assert data2[0]['numbers']==data[0]['numbers']\n",
    "pd.testing.assert_frame_equal (data2[0]['table'], data[0]['table'])\n",
    "np.testing.assert_array_equal (data2[0]['vector'], data[0]['vector'])\n",
    "pd.testing.assert_frame_equal (data2[1], data[1])\n",
    "assert data2[2]==data[2]\n",
    "pd.testing.assert_frame_equal (data2[3], data[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsforecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
