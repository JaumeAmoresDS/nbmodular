{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function_io\n",
    "\n",
    "> I/O functions used for loading / saving results and local variables from function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core.function_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pdb\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "import shlex\n",
    "from dataclasses import dataclass\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import ast\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "from IPython import get_ipython\n",
    "from IPython.core.magic import (Magics, magics_class, line_magic,\n",
    "                                cell_magic, line_cell_magic)\n",
    "from IPython.core.magic_arguments import (argument, magic_arguments, parse_argstring)\n",
    "import ipynbname\n",
    "from sklearn.utils import Bunch\n",
    "from fastcore.all import argnames\n",
    "import nbdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_df (path, **kwargs):\n",
    "    if (path.parent / f'{path.name}.parquet').exists():\n",
    "        df = pd.read_parquet (path.parent / f'{path.name}.parquet', **kwargs)\n",
    "    elif (path.parent / f'{path.name}.pk').exists():\n",
    "        df = pd.read_parquet (path.parent / f'{path.name}.pk', **kwargs)\n",
    "    elif (path.parent / f'{path.name}.csv').exists():\n",
    "        df = pd.read_parquet (path.parent / f'{path.name}.csv', **kwargs)\n",
    "    else:\n",
    "        raise RuntimeError (f'File {path} not found')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_df (df, path, **kwargs):\n",
    "    path.parent.mkdir (parents=True, exist_ok=True)\n",
    "    name_without_extension = path.name[:-len('.df')]\n",
    "    extension = ''\n",
    "    try:\n",
    "        df.to_parquet (path.parent / f'{name_without_extension}.parquet', **kwargs)\n",
    "        extension='parquet'\n",
    "    except:\n",
    "        try:\n",
    "            df.to_pickle (path.parent / f'{name_without_extension}.pk', **kwargs)\n",
    "            extension='pickle'\n",
    "        except:\n",
    "            df.to_csv (path.parent / f'{name_without_extension}.csv', **kwargs)\n",
    "            extension='csv'\n",
    "    with open (path, 'wt') as f: \n",
    "        f.write (extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_pickle (path, **kwargs):\n",
    "    return joblib.load (path, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_pickle (data, path, **kwargs):\n",
    "    joblib.dump (data, path, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_csv (path, **kwargs):\n",
    "    return pd.read_csv (path, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_csv (df, path, **kwargs):\n",
    "    df.to_csv (path, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_parquet (df, **kwargs):\n",
    "    return pd.read_parquet (path, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_parquet (df, path, **kwargs):\n",
    "    df.to_parquet (path, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load (\n",
    "    path_variables,\n",
    "    io_type='pickle',\n",
    "    **kwargs,\n",
    "):\n",
    "    load_function = eval (f'load_{io_type}')\n",
    "    return load_function (path_variables, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save (\n",
    "    data,\n",
    "    path_variables,\n",
    "    io_type='pickle',\n",
    "    **kwargs,\n",
    "):\n",
    "    Path(path_variables).parent.mkdir (parents=True, exist_ok=True)\n",
    "    save_function = eval (f'save_{io_type}')\n",
    "    return save_function (data, path_variables, **kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsforecast",
   "language": "python",
   "name": "tsforecast"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
